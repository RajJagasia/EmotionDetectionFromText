{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-zZ8Esdip1s",
        "outputId": "80390812-34cc-4d46-9bed-b98e488387f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.33.4.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from ktrain) (23.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp39-cp39-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/lib/python3/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok>1.3.3\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting transformers>=4.17.0\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.9/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->ktrain) (3.15.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.33.4-py3-none-any.whl size=25314185 sha256=424374584d0b06af4f0e936a1f8e134c4e7a23dc046259ea65c21f383fa20ab4\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/27/03/f1e0181d2c6296133f8d3cc5ddee265094de0dd90a5755de87\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=0b5033d8a89492922a4d622f28460d1fed821f5a334ca0c561ec172c0f838578\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/26/24/14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12303 sha256=7fe6a276c1402331e54816a31ac6bd19359a7743191ea9c0d361e1ec3f8f7444\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/d6/d1/c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=404010c0defdd14966abd8947a444f7df6133452b256c18e782bd7421d0b23fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/25/02/4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4666 sha256=24c3dc237f475dd8ea2ed4b5473c2726c51f94fb7c3e150164964010b37a6504\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/df/15/a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14992 sha256=01c2afdd11e67035abfc304068e483971b2a7690e757cd12a13f5ef73987e64c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/85/50/f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6958 sha256=cf3b4766b63362e744a2c49d5d118e8f2a30c1adae06a7e02dbbde6dd8e1c18a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/8c/9a/917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=25f215a7421b24c0161ba7467f2c9a98e4ac0c5187ff0d9d74252a349f4589a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/36/25/efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18910 sha256=912191f83abe20d438a2e26a475b6eb08c423d10811df449f3da25a7abd3f5ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/c1/84/b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993243 sha256=781a5b8de87cd486797fa0589515a674dc4edfc0290d9cce3d5af17d6787a29f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect\n",
            "Installing collected packages: whoosh, tokenizers, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.13.3 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.33.4 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tokenizers-0.13.2 transformers-4.27.3 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NawlDtYDol0e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwYkdeAHpv_K",
        "outputId": "a37b41c5-0201-4914-bb6d-e3c38871f831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/drive/MyDrive/tweet_and_emotion.csv\")"
      ],
      "metadata": {
        "id": "4Vim8D9k1mYS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPLWe-kS11x2",
        "outputId": "07cfc178-64d9-4227-b8ee-11f64d847689"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10624, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.emotions.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alZfirfB2i1i",
        "outputId": "042ad107-251a-46b3-ac15-14873fb407dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fear       2252\n",
            "neutral    2238\n",
            "sadness    2198\n",
            "joy        2125\n",
            "anger      1811\n",
            "Name: emotions, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yOrTgca_qXIO"
      },
      "outputs": [],
      "source": [
        "data_set = df['tweet']\n",
        "target= df['emotions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TkbChT8GqZ_v"
      },
      "outputs": [],
      "source": [
        "class_names = [\"fear\",\"neutral\",\"sadness\",\"joy\",\"anger\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fx-Jw5LLqzMh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(data_set, target , test_size=0.2 ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "coB68QHlrV_K"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.tolist()\n",
        "x_test = x_test.tolist()\n",
        "\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5lpGHJt_rYho"
      },
      "outputs": [],
      "source": [
        "encoding = {\n",
        "  \"fear\":0,\n",
        "  \"neutral\":1,\n",
        " \"sadness\":2,\n",
        "  \"joy\":3,\n",
        " \"anger\":4,\n",
        "}\n",
        "\n",
        "# Integer values for each class\n",
        "y_train = [encoding[x] for x in y_train]\n",
        "y_test = [encoding[x] for x in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TQzArlVgrdZT",
        "outputId": "f988fb98-2b15-49bf-c6f3-d1cc47f9939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: text classification\n"
          ]
        }
      ],
      "source": [
        "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=class_names,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=350, \n",
        "                                                                       max_features=35000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuuSs5bZrlJv",
        "outputId": "c2aa83e5-be41-425a-d9bf-d699da04680e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ],
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1niUYXV8w6x4",
        "outputId": "c2dc514a-74c6-4703-bea7-fd647aa0f156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input-Token (InputLayer)       [(None, 350)]        0           []                               \n",
            "                                                                                                  \n",
            " Input-Segment (InputLayer)     [(None, 350)]        0           []                               \n",
            "                                                                                                  \n",
            " Embedding-Token (TokenEmbeddin  [(None, 350, 768),  23440896    ['Input-Token[0][0]']            \n",
            " g)                              (30522, 768)]                                                    \n",
            "                                                                                                  \n",
            " Embedding-Segment (Embedding)  (None, 350, 768)     1536        ['Input-Segment[0][0]']          \n",
            "                                                                                                  \n",
            " Embedding-Token-Segment (Add)  (None, 350, 768)     0           ['Embedding-Token[0][0]',        \n",
            "                                                                  'Embedding-Segment[0][0]']      \n",
            "                                                                                                  \n",
            " Embedding-Position (PositionEm  (None, 350, 768)    268800      ['Embedding-Token-Segment[0][0]']\n",
            " bedding)                                                                                         \n",
            "                                                                                                  \n",
            " Embedding-Dropout (Dropout)    (None, 350, 768)     0           ['Embedding-Position[0][0]']     \n",
            "                                                                                                  \n",
            " Embedding-Norm (LayerNormaliza  (None, 350, 768)    1536        ['Embedding-Dropout[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Embedding-Norm[0][0]']         \n",
            " on (MultiHeadAttention)                                                                          \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Embedding-Norm[0][0]',         \n",
            " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-1-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-1-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-1-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-1-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-2-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-2-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-2-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-2-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-2-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-3-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-3-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-3-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-3-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-3-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-3-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-4-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-4-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-4-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-4-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-4-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-4-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-5-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-5-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-5-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-5-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-5-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-5-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-5-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-5-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-6-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-6-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-6-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-6-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-6-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-6-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-6-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-6-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-7-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-7-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-7-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-7-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-7-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-7-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-7-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-7-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-8-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-8-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-8-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-8-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-8-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-8-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 350, 768)    2362368     ['Encoder-8-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 350, 768)    0           ['Encoder-8-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-9-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 350, 768)    1536        ['Encoder-9-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward (FeedFor  (None, 350, 768)    4722432     ['Encoder-9-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Dropout   (None, 350, 768)    0           ['Encoder-9-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Add (Add  (None, 350, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-9-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Norm (La  (None, 350, 768)    1536        ['Encoder-9-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 350, 768)    2362368     ['Encoder-9-FeedForward-Norm[0][0\n",
            " ion (MultiHeadAttention)                                        ]']                              \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-9-FeedForward-Norm[0][0\n",
            " ion-Add (Add)                                                   ]',                              \n",
            "                                                                  'Encoder-10-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 350, 768)    1536        ['Encoder-10-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward (FeedFo  (None, 350, 768)    4722432     ['Encoder-10-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Dropout  (None, 350, 768)    0           ['Encoder-10-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Add (Ad  (None, 350, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-10-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Norm (L  (None, 350, 768)    1536        ['Encoder-10-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 350, 768)    2362368     ['Encoder-10-FeedForward-Norm[0][\n",
            " ion (MultiHeadAttention)                                        0]']                             \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-10-FeedForward-Norm[0][\n",
            " ion-Add (Add)                                                   0]',                             \n",
            "                                                                  'Encoder-11-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 350, 768)    1536        ['Encoder-11-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward (FeedFo  (None, 350, 768)    4722432     ['Encoder-11-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Dropout  (None, 350, 768)    0           ['Encoder-11-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Add (Ad  (None, 350, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-11-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Norm (L  (None, 350, 768)    1536        ['Encoder-11-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 350, 768)    2362368     ['Encoder-11-FeedForward-Norm[0][\n",
            " ion (MultiHeadAttention)                                        0]']                             \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 350, 768)    0           ['Encoder-11-FeedForward-Norm[0][\n",
            " ion-Add (Add)                                                   0]',                             \n",
            "                                                                  'Encoder-12-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 350, 768)    1536        ['Encoder-12-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward (FeedFo  (None, 350, 768)    4722432     ['Encoder-12-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Dropout  (None, 350, 768)    0           ['Encoder-12-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Add (Ad  (None, 350, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-12-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Norm (L  (None, 350, 768)    1536        ['Encoder-12-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Extract (Extract)              (None, 768)          0           ['Encoder-12-FeedForward-Norm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " NSP-Dense (Dense)              (None, 768)          590592      ['Extract[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 5)            3845        ['NSP-Dense[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,361,669\n",
            "Trainable params: 109,361,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zc4NneNsrqlD"
      },
      "outputs": [],
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), \n",
        "                             val_data=(x_test, y_test),\n",
        "                             batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaaxy4L4r-wz",
        "outputId": "71cbf3d3-ac56-44b4-c24f-0a5af5453285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n",
            "Epoch 1/1024\n",
            "1417/1417 [==============================] - 775s 528ms/step - loss: 4.7338 - accuracy: 0.2842\n",
            "Epoch 2/1024\n",
            "1417/1417 [==============================] - 2s 755us/step - loss: 55.7390 - accuracy: 0.2222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ktrain/lroptimize/lrfinder.py:267: UserWarning: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.\n",
            "  warnings.warn(str(e))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
          ]
        }
      ],
      "source": [
        "learner.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RgA8gJHrr_0v",
        "outputId": "21c3837c-45d1-48df-ae14-d5c76e57818b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "learner.lr_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRETXT_ZrwN5",
        "outputId": "261cf6bc-d7eb-4a6b-de3d-43821c13f8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/3\n",
            "1417/1417 [==============================] - 839s 577ms/step - loss: 1.2883 - accuracy: 0.4562 - val_loss: 0.7734 - val_accuracy: 0.7125\n",
            "Epoch 2/3\n",
            "1417/1417 [==============================] - 834s 589ms/step - loss: 0.6475 - accuracy: 0.7646 - val_loss: 0.5885 - val_accuracy: 0.7784\n",
            "Epoch 3/3\n",
            "1417/1417 [==============================] - 834s 589ms/step - loss: 0.4000 - accuracy: 0.8557 - val_loss: 0.6207 - val_accuracy: 0.7802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f845bdf5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "learner.fit_onecycle(1e-5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1icWjKA_Th6V",
        "outputId": "fa36d0b7-db4d-4a3b-b923-f605ec24a564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 67s 928ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fear       0.82      0.86      0.84       436\n",
            "     neutral       0.69      0.76      0.72       443\n",
            "     sadness       0.73      0.69      0.71       431\n",
            "         joy       0.83      0.79      0.81       444\n",
            "       anger       0.85      0.80      0.83       371\n",
            "\n",
            "    accuracy                           0.78      2125\n",
            "   macro avg       0.78      0.78      0.78      2125\n",
            "weighted avg       0.78      0.78      0.78      2125\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[375,  14,  24,   7,  16],\n",
              "       [ 12, 337,  45,  40,   9],\n",
              "       [ 30,  67, 297,  17,  20],\n",
              "       [ 17,  56,  13, 351,   7],\n",
              "       [ 24,  17,  26,   6, 298]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "learner.validate(val_data=(x_test, y_test), class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PvrtV5E8aFQK"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmDs41h-VWTs"
      },
      "outputs": [],
      "source": [
        "predictor.save(\"models/tweet_emotion_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}